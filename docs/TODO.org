;;;; -*- Mode: org; indent-tabs-mode: nil; coding: utf-8; show-trailing-whitespace: t -*-
* 0.5.1 Test loading (including fresh recompilation) of all the libraries in quicklisp.
** Test loading of every ASDF system and publish results in db.lisp.
  This means even if the library doesn't have a test suite,
  or the test suite is not yet integrated into the test-grid,
  we will know it's compilation status.

  Complications: one project may have more than one ASDF system,
  and in such case it's not clear how to relate compilation
  failures with test suite status, if only part of ASDF systems
  failed to compile.

** DONE Change agent to perform load test of every ASDF system in Quicklisp
   CLOSED: [2012-09-01 06:43]
** DONE Continuable test runs
   CLOSED: [2012-09-04 Вт 02:06]
   Don't loose test run results if it was interrupted (due to errors, network outage or agent termination)
** DONE Workaround the GAE issue https://code.google.com/p/googleappengine/issues/detail?id=8032
   CLOSED: [2012-09-04 Вт 02:05]
** DONE rework ABCL report
   CLOSED: [2012-09-14 Пт 06:39]
** DONE make sure old reports work when DB contains ASDF systems load results
   CLOSED: [2012-09-10 06:43]
** TODO collect results for libraries missed in Quicklisp 2012-09-09 results
   Some are missed because of agent bug: list of project was retrieved
   from wrong (old) quicklisp:
     cartesian-product-switch, cl-cheshire-cat, cl-grace, coleslaw,
     com.clearly-useful.iterator-protocol,
     com.clearly-useful.protocols, com.clearly-useful.sequence-protocol,
     formlets, glu-tessellate, infix-dollar-reader, lambda-lift,
     optima, place-modifiers, pzmq.

   bknr-datastore testsuite was not run because it was added to testgrid
   as bknr.datastore.
** TODO rework quicklisp diff report
   <in progress>
** TODO rework ECL reports
** TODO The list of projects to test should be reteieved from the quicklisp
        tested by agent in child processes, but not the quicklisp used
        to run the agent itself.
** TODO The OpenVRP workaround (https://github.com/quicklisp/quicklisp-client/issues/61)
        should be done so that it only applies to quicklisp 2012-08-11,
        but not to any other (fixed in starting from quicklisp 2012-09-09).
** TODO when killing child process, sometimes we may have "No such process" simple-error
   if the process already finished. Handle it.
** TODO Timeout detection should sustain laptop hibernation
** TODO remove the :load-failed status
** TODO document the new version of agent (how to run it, that it takes long and may be restarted)
** TODO increase load-test timeout
* 0.5.4 Introduce an option to limit agent run time
  Use case: someone wants to run agents at night, but have
  the machine free from agent during dayly work.
  We will provide and option the user can configure in run-agent.lisp
  which limits agent run time so that agent exits after this duration.

  Before terminating agent should sumbit the results accumulated to server
  (even partial test runs). This is necessary becase we can not
  be sure the user will ever start the agent again.

  This also means that if next time agent is started, it should
  know what part of test run is completed, and continue for
  remaining projects (record the completenes status
  per library in persistence.lisp instead of whole
  quicklisp distros?)
* 0.5.5 Install more lisps on my VPS
  I already have acl 8.2a express, ccl 1.8, sbcl 1.57, ecl from git, cmucl 20c
** DONE ABCL
   CLOSED: [2012-08-20 Пн 01:48]
** TODO CLISP (build a multithreaded version)
* 0.6.0 Reports Improve 2
** TODO combine information about load failures with information about system dependencies
   It will allow us to find "root" compilation blockers -
   the libraries which do not compile and block other libraries
   compilation.

   After the milestone 0.5.1 we will have compilation status
   for all the ASDF systems in quicklisp on all the lisp implemetations.

   If we combine the compilation statuses with the dependency
   information, it will become visible, what libraries should
   be fixed first to make certain lisp implementation wider adopted.

   Of course, quicklisp download statistics we have already
   provides some information about "importance" of libraries,
   but the dependency information will make the situation more clear.

   This feature is suggested by Juan Jose - the ECL maintainer.


   We now have information which ASDF systems fail to load on particular Lisps
   (this is implemented for the 56 libraries already included into the test-grid,
   and After the milestone 0.5.1 we will have compilation status
   for all the ASDF systems in quicklisp on all the lisp implemetations).

   But ASDF systems depend on each other, so if system A fails to load,
   all other systems which depend on A directly or indirectly fail to load as well.
   So if we just list all the load failures, we are going to have large list, but will
   be unable to see where the real problem is, what is necessary to fix.

   The idea is to combine the information about load failures with information
   about dependencies to find out the root "blockers" - the libraries failing by
   themselves and blocking others.

   To do so we may just sort the ASDF systems by dependencies
   (https://en.wikipedia.org/wiki/Topological_sorting), and the root blockers
   will be at the top of the list.

   I envision simple report in the form

   system-a: blocked-by: <list of failed systems on which system-a depends>; blocks <list of failed systems depending on system-a>
   system-b: blocked-by: <list of failed systems on which system-b depends>; blocks <list of failed systems depending on system-b>
   ...

   While the real data is not available, you can just hardcode
   two stub functions:
   (load-failed-p <system name>) => true or false,
   and
   (dependencies <system name>) => list of systems on which the given system depends.

   With hardcoded stub information we may already experiment and develop with the report.

   Also, we can extract the dependency information for the real implementation
   of the DEPENDENCIES function. It may be done either by loading
   every system and querying ASDF, or from quicklisp - see file quicklisp\dists\quicklisp\systems.txt
   in your quicklisp installation. Note, there is no way to detect 100% exact
   dependency information, because .asd files are just lisp code,
   and some of them just do (asdf:operate 'asdf:load-op 'something)
   instead of putting something to :depend-on clause of defsystem macro.
   But the information which IS possible to extract will give us good results
   I believe.

** TODO make lisp code the main and the easiest interface to the test results:
   convenient interation, filtering and matching functions.
   We want to add to every HTML report a secion with lisp
   code generating this report, so that all the users
   see and understand how to query data and can follow
   these examples.
** DONE document the data format, data access functions, reporting
   CLOSED: [2012-08-17 Пт 21:47]
   functions and utilities.
** TODO the diff report (aka regressions report) - diff along various dimentions
   Currently we can only find differences between test statuses
   of a library on different quicklisps, when the lisp implementation
   version is a constant.
   We should generalize this to compare test results on two 
   different versions of a compiler (windows/linux or old compiler
   version and new one). Also when comparing test results, 
   we must be more flexible than matching results only of
   exactly the same lisp-implementation-identifier, 
   because we don't always has exactly this lisp.
   For example when we compare the lates qicklisp version
   with the previous one, we may want to consider ecl-12.7.1-dee2506a-linux-x86-lisp-to-c
   and ecl-12.7.1-xxxxffff-linux-x86-lisp-to-c as the same compiler, 
   because otherwise we might just have no results to compare.

   In other case, we want to compare test results of these two
   compilers. Then we consider them different and 
   different sides of comparision: one on the left hand,
   and another on the right side.
   
   At first sight the task may be solved
   by parametrizing the report by two functions:
   - the one which decides what results to put to left side and to right side
   - a predicate which decides if a result cell from the left side is comparable 
     to a result from the right side.

** TODO library mainainer page:                             :report:informer:
   with reports about the test statuses
   for this single library on various platforms with
   various quicklisp versions,
   history of regressions (by quicklisp versions)

   There is some draft (uncommited) code for this task.

** TODO Prevent HTML injection via test-run-info                     :report:
** TODO Apply for a subdomain at common-lisp.net, e.g. test-grid.common-lisp.net,
   It is another way to solve the security issue with HTML injections,
   because in this case web browser keeps test grid reports in different
   security domain than other common-lisp.net pages.
** TODO pivot reports: make row header column always visible
** DONE limit amount of data included into to HTML reports to the last 3 quicklisp releases 
   CLOSED: [2012-08-15 Ср 20:42]
   to improve the page performance and load time.
** TODO kind of burndown chart: avearange number of bugs by time
** TODO visual graph of library dependencies, clickable (SVG?),
        so that we can see what libraries are blocked when
        the given library is broken, and what dependencies
        block this library.
        Look for help from http://chart.ravenbrook.com/ ?
** TODO has-regressions-p - cover all the possible cases by unit tests?
** TODO Filters for pivot reports
   Partially done - in a non interactive way.
   I.e. I apply filters when generate reports to publish,
   but there is no way to filter them on WEB. The
   only way for user is to checkout lisp code and
   use it's own filters. Not that bad way, especially
   in the ideology that Lisp is the main interface to
   test results.

   Do we really need WEB UI for filters? If so, it
   is low priority anyway.

* 0.7.0 Add more test suites
** TODO add testsuites of more libraries from quicklisp

    See the following files in the "docs" directory:

    test-systems - list of all the ASDF systems in Quicklisp
           with a word "test" in the system name;
           ordered by the project download count.

    detect-test-systems.lisp - the lisp code which
          generated the test-systems file

    quicklisp-download-statistics-2012.txt - quiclisp download statistics

    coverage.org - information about the libraries already reviewed:
          whether it is added to test grid, and if not added - why
         (no test suite, needs manual configuration, hangs, etc.)
          The libraries are ordered in alphabetical order.

** TODO create drakma test suite - will ensure drakma works on all the lisps.
    Drakma test suite is a must. HTTP client today is as vital thing
    as file system access. It should work on all the lisps.
    Create a test suite, the simples one - download one file
    form common-lisp.net. And make sure it works on all the lisps.
* 0.7.1 Add ANSI test suite?
  Does not depend on quicklisp distro version; but BTW may be distirbuted via quicklisp.
* 0.8.0 Move online log storage to Amazon S3 from Google App Engine?
  We are already close to limit of free GAE resources
  (mostly on datastore write operations, several of which
  are performed for every uploaded log, and when testing
  quicklisp we upload thousands of logs).

  Payed GAE plan costs minimum $15 per month.

  Amazon S3 costs $0.12 per GB per month - much cheaper
  (whole quicklisp by singl lisp implementation produces
  2-5 MB of logs).

  Also we have seen GAE stability/user support issues.

  Problem: uploading logs is easy usin zs3 library,
  but how to assing unique identifiers to them?
  S3 doesn't provide such a functionality. We would
  like to avoid another service only for identifier
  generation. Randome identifiers seems good, but
  we must resovle possible collisions. Maybe calculate
  MD5 for every log before submit and compare with
  ETag returned by S3 in HTTP header? Can it help?

* 0.9.0 Test source control HEADs of libraries, not only quicklisp releases
** TODO a way to specify lib-wold as a quicklisp version with some
   library versions overriden (checkout this particular
   libraries from the scm), so that library author can quickly
   get test result for his changes (fixes)  in scm.
   An implementation idea to consider: almost every scm allows
   to download asnapshot via http, so the quicklisp http machinery may
   be reused here, whithout running a shell command for
   checkout.
   40h

* 0.10.0 Automate test results publishing process, send notification when regressions occur
* 0.11.0 For all the libraries which need specific environment
   (like cffi, cl-sql) correctly detect the absense of required
   envorinment and return :NO-RESOURCE status and provide guiding message to the
   user how to configure them (log to the output test output?).

   This may be implemented by invoking generic function
   (test-grid-testsuites:check-enviroment <library-name> <test-enviroment-object>) => :NO-RESOURCE or :OK,
   by default returns :OK, but the library maintainer
   may define a method for his library which checks for available envoriment
   and return :NO-RESOURCE, or if the enviroment is OK
   returns :OK and may store some data on the test-envormment-object.

   Then (test-grid-testsuites:libtest <library-name> <test-enviroment-object>) is
   called by agent. So the check-envoronment method may pass enviroment
   information (for examle DB connection parametrs for cl-sql) to the test suite.

   Also we need to define a way for check-enviromnent to be configured
   by the end-user who runs the agent, because every installation
   may have different DB connection parameters. For example, check-enviroment
   may load a file <workdir>/test-configs/<library-name>-config.lisp.
   This file is expected to be provided by the user who runs agant
   and is willing to spend an extra effort to contribute test
   results for these libraries (this is optional of course).

   We may provide only the API and leave the implementation
   of check-environment methods to the library maintainers, because
   othersize it may take very long time for us to impelement
   it for all such libraries.

   Although, for the most important libraries which don't have
   enough maintainers we could provide implementation.
* lisp-agent postponed issues
** TODO memoization of the implementation-identifier generic function is not portable
   in particular, it's known that fare-memoization can't memoize it on ACL,
   see https://groups.google.com/d/topic/cl-test-grid/Vnl3kHJbQ0M/discussion
** TODO when logging the name of a library currently being tested, log also it's number in the
   total number of libraries, e.g. [41 of 56].
** TODO remove the old test-runs, quicklisp directordires and ~/cl-test-grid-settings.lisp
   Do it autmatically, or send email to all the contributors, or just ignore this issue
** TODO contributor monthly summary.
   Now that test grid agent can be run by cron, sending confirmation
   email to contributor for every test result doesn't make sense,
   because the contributor is anaware when testing happens. But providing
   feedback is necessary. We may send a monthly digest to contributor
   summarizing the test results received from his agent(s). May be implemented
   as a cron task running say at the 8th of every month (so that admin has
   time to commit all the resutls to db.lisp and the digest
   producer task sees them). Admin should be BCC'ed in these emails.
   Should it be a single email for all contributors and the mailing list,
   or each contributor should be emailed individually?
** TODO a parameter to the main function: limit the maximum time the agent works
** DONE ensure the tesg-grid-testsuites code is recompiled when necessary
   CLOSED: [2012-08-15 Ср 19:11]
   The libraries being tested are recompiled at every test run.
   It would be good to ensure test-grid-testsuites code is also correctly
   recompiled.
   Related thread on asdf-devel:
   http://lists.common-lisp.net/pipermail/asdf-devel/2012-July/002548.html
** TODO Admin stores a hashmap for lisps to be tested (or skipped)
    by particular agent in the aget sources (note, the agent
    updates the source every time from git) This allows to distribute work
    between agents having overlaping sets of lisp implementations.
    Need a mechanizm for announcing the lisps present on
    agent (probably just add agent-id to the test run
    description submitted form agent to admin, and this as an announcement).
    As the compilers versions are changed, probably the
    hashmap to store responsibility specifications should
    contain not full lisp implementation identifier,
    but only generic name, like SBCL instead of SBCL 1.0.57.
    But allow for ECL-bytecode to be distingueshed from
    ECL-lisp-to-c. I.e. in the end we can get some kind
    of patterns for lisp implementation identifier. And
    the identifier will be a structured object, not just
    a string; provably it will even contains *features*
    of the lisp implementaion.
** TODO Agent: retry when test results upload failed.
** TODO recompile cl-test-grid-agent sources at every agetn run?
   As currently ASDF doesn't rebuild depending libraries
   when the libraries they depend on changed (add
   links to this TODO item when Internet connection
   will be up)
   Related thread on asdf-devel:
   http://lists.common-lisp.net/pipermail/asdf-devel/2012-July/002548.html
** TODO kill process tree on unix in case the test suite exceeded timeout
   Currenlty we only kill the lisp process, but not it's children.
   Some test suites may start other programs, and it makes sense
   to kill the testsuite child process too. Implementation hint:
   the most portable API on unix to find out child processes,
   as it seems to be, is the ps program. We will need to
   implement a shell script killtree.sh <pid> which uses
   ps to find all descendents and kill them. Portable format
   of ps arguments should be used.
** TODO move test-grid::print-log-footer to the test-grid-agent package,
   and call it only form the agent process, not from the child, test suite
   running, process.
** TODO consider what test suite timeout value is the best (30 mins currently)
** DONE backtrace in logs
   CLOSED: [2012-08-15 Ср 19:09]
** TODO should the lisp-process-timeout condition inherit from serous-condition, error, or just condition?

** DONE Prevent child lisp process entering debugger.
   CLOSED: [2012-08-15 Ср 19:09]
   Note, different lisps treat unhangled signals during -eval
   differently: ECL exits with status 1, CCL enters debugger
   and hangs.
** TODO program parameters escaping is not perfect. When we
   run CLISP as an external process, it can not stand
   string literals with " inside.
** TODO enable/disable program parameters escapting depending on the
   external-program behaviour (consider also using input stream
   of the lisp process, or a temporary file)
** TODO prevent test run directory names conflict (currently they
   are named by timestamp with resolution to seconds)
** TODO temp file naming: ensure unique [probably specify random-state]
** TODO persistence.lisp format - sort and newline for every record

* User Requests
** TODO Vladimir Sedach: test multithreaded CLISP
   (less important now as Vladimir already installed such lisp on his
   machine and contributes tests)
** TODO Luis Oliveira: buld library heads from source control
* Backlog
** TODO Reuild free the lisps from source control daily, before running test-grid-agent
** TODO Enable HTTP caching for library test logs (good recipe: https://developers.google.com/speed/docs/best-practices/caching)
** TODO add CCL revision to the version string (I have impression
   that CCL versions checked out at different time from the official release SVN
   svn co http://svn.clozure.com/publicsvn/openmcl/release/1.8/darwinx86/ccl
   may be different. I.e. despite it is called "release 1.8", the mainteiners
   commit fixes there, and the version string we use now - "ccl-1.8-f95-linux-x86",
   does not reflect this. In other words, our version string does not
   identify CCL uniquly.
** TODO code coverage: SBCL provides sb-cover. Integrate it somehow
        and publish in the reports.
        How?
        - extend the lib-result object with one more field, percentage 
          of the covered lines?
        - separate report?
        - or just output the information into the log?
** TODO osicat: automate the :no-resource condition
** TODO ABCL, cffi tests: return :no-resource if JNA is not available
** TODO cffi tests: return :no-resource if C compilation fails on linux
** TODO cl-fad and flexi-streams use c:\tmp as a temporary directory
   on Windows; it's not very good. Maybe try to provide them
   with a temporary directory inside of the cl-test-grid working
   dir?
** DONE Do not allow empty contributor contact in test results. Instead
   CLOSED: [2012-08-20 Пн 01:56]
   always ask the contributor to provide something, nickname,
   whatever.
** TODO quicklisp distro version in report headers may be a link to
   list of library versions in this ql version
   (like this: http://www.quicklisp.org/beta/releases.html, but
   it's only for the latest QL).
** TODO report overview: change "represents every test run as a separate row"  :report:overview:
   to
   "represents every <tt>test-grid:run-tests</tt> as a separate row"
   (after user will know this command from the main project description)
   ?
** TODO Description of CSV report may link to an example of the CSV report  :report:overview:
   imported to a Google Spreadsheet
   with pivot calculating avearage duration of 
   tests for every library.
** TODO spell check the reports-overview                    :report:overview:
** TODO quick access to the test run info from the pivot report table cell  :report:pivot:
   (or maybe just print the test run info to the log, like a header;
    but it is a duplication and also we will have invonviniences
    if we want to modify this infromation in the lob BLOB)
** TODO reduce non cl-test-grid output in the console (quicklisp output,
   compiler output, etc), so that cl-test-grid messages to the user
   are better visible.
** TODO Limit library output file size (how?).
** TODO finalize the terminology we use in the code
   to refer our main data:
   - test status for a particular library
   - library test result object (includes the status
     as well as log length, the key of the log
     in the online blob store, probably the
     library test duration)
   - list of library test results in a particular test
     run
   - test run description, consists of lisp name,
     libraries set (think quicklisp distro),
     the user contacts, total test run duration,
     etc.
** TODO when GAE quotas (for requests, emails, anything else)
   are exceeded, recognize it and display a meaningfull
   message to the user.
** TODO usocket test suite might need manual configuration,
   see their README. Distinguish the case
   when the manual configuration hasn't been
   performed and return :no-resource status.
** TODO An utility to delete blobs not used in db.lisp from the blobstore :server:


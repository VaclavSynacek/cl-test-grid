;;;; -*- Mode: org; indent-tabs-mode: nil; coding: utf-8; show-trailing-whitespace: t -*-
* 0.6.0 Reports Improve 2
** DONE combine information about load failures with information about system dependencies
   CLOSED: [2012-10-01 Пн 07:12]
   It will allow us to find "root" compilation blockers -
   the libraries which do not compile and block other libraries
   compilation.

   After the milestone 0.5.1 we will have compilation status
   for all the ASDF systems in quicklisp on all the lisp implemetations.

   If we combine the compilation statuses with the dependency
   information, it will become visible, what libraries should
   be fixed first to make certain lisp implementation wider adopted.

   Of course, quicklisp download statistics we have already
   provides some information about "importance" of libraries,
   but the dependency information will make the situation more clear.

   This feature is suggested by Juan Jose - the ECL maintainer.


   We now have information which ASDF systems fail to load on particular Lisps
   (this is implemented for the 56 libraries already included into the test-grid,
   and After the milestone 0.5.1 we will have compilation status
   for all the ASDF systems in quicklisp on all the lisp implemetations).

   But ASDF systems depend on each other, so if system A fails to load,
   all other systems which depend on A directly or indirectly fail to load as well.
   So if we just list all the load failures, we are going to have large list, but will
   be unable to see where the real problem is, what is necessary to fix.

   The idea is to combine the information about load failures with information
   about dependencies to find out the root "blockers" - the libraries failing by
   themselves and blocking others.

   To do so we may just sort the ASDF systems by dependencies
   (https://en.wikipedia.org/wiki/Topological_sorting), and the root blockers
   will be at the top of the list.

   I envision simple report in the form

   system-a: blocked-by: <list of failed systems on which system-a depends>; blocks <list of failed systems depending on system-a>
   system-b: blocked-by: <list of failed systems on which system-b depends>; blocks <list of failed systems depending on system-b>
   ...

   While the real data is not available, you can just hardcode
   two stub functions:
   (load-failed-p <system name>) => true or false,
   and
   (dependencies <system name>) => list of systems on which the given system depends.

   With hardcoded stub information we may already experiment and develop with the report.

   Also, we can extract the dependency information for the real implementation
   of the DEPENDENCIES function. It may be done either by loading
   every system and querying ASDF, or from quicklisp - see file quicklisp\dists\quicklisp\systems.txt
   in your quicklisp installation. Note, there is no way to detect 100% exact
   dependency information, because .asd files are just lisp code,
   and some of them just do (asdf:operate 'asdf:load-op 'something)
   instead of putting something to :depend-on clause of defsystem macro.
   But the information which IS possible to extract will give us good results
   I believe.

** DONE the diff report (aka regressions report) - diff along various dimentions
   CLOSED: [2012-10-01 Пн 08:26]
   Currently we can only find differences between test statuses
   of a library on different quicklisps, when the lisp implementation
   version is a constant.
   We should generalize this to compare test results on two
   different versions of a compiler (windows/linux or old compiler
   version and new one). Also when comparing test results,
   we must be more flexible than matching results only of
   exactly the same lisp-implementation-identifier,
   because we don't always has exactly this lisp.
   For example when we compare the lates qicklisp version
   with the previous one, we may want to consider ecl-12.7.1-dee2506a-linux-x86-lisp-to-c
   and ecl-12.7.1-xxxxffff-linux-x86-lisp-to-c as the same compiler,
   because otherwise we might just have no results to compare.

   In other case, we want to compare test results of these two
   compilers. Then we consider them different and
   different sides of comparision: one on the left hand,
   and another on the right side.

   At first sight the task may be solved
   by parametrizing the report by two functions:
   - the one which decides what results to put to left side and to right side
   - a predicate which decides if a result cell from the left side is comparable
     to a result from the right side.

  ==============
  The solution:
  - select two sets of results
  - compute exclusive-or of them
  - print pivot with necessary columns and rows

  Example is the compiler-diff report and quicklisp-diff

** DONE limit amount of data included into to HTML reports to the last 3 quicklisp releases 
   CLOSED: [2012-08-15 Ср 20:42]
   to improve the page performance and load time.
** DONE remove the :load-failed status from DB and reporting
   CLOSED: [2012-10-01 Пн 08:48]
** DONE document the lisp functions for test results access and report generation,
   CLOSED: [2012-10-08 Пн 09:03]
   provide source code examples
** DONE describe the load-failures, the compiler-diff and quicklisp-diff
   CLOSED: [2012-10-08 Пн 09:14]
   reports on the reporting page

   Sketch of the reporing page structure:

   - data collected by test-grid
   - how to load the data: repository and ASDF systems
     git clone
     git clone
     asdf:*central-regitsty*
     (*db* (load-db))
     (in-package :test-grid-reporting)

   - simpliest list-failures example:

   - diffs:
     compiler diff
     quicklisp diff

   - representation tools: pivots

   - load failures + dependencies

** DONE different result-spec for known failures? and different color
   CLOSED: [2012-10-09 Вт 08:22]
** DONE library mainainer page
   CLOSED: [2012-10-13 Сб 22:54]
   with reports about the test statuses
   for this single library on various platforms with
   various quicklisp versions.

** TODO [2 h] remove or wrap nicely the global variable *failures* from the dependencies-and-blockers.lisp
** TODO [6 h] Prevent HTML injection via test-run-info
** TODO [4 h] document, for each CL community role, how he can benefit from testgrid
   - library mainaner:
     - Status of your library ASDF systems loaded by various lisps
     - If you have a testsuite, results of your test suite on various lisps
     - Updated with every quicklisp distro
     - Regressions (desirable to show regression
       history along quicklisp versions).
   - lisp implementation maintener
     - How you lisp is supported by libraries
     - What libraries are most importatn to fix,
       to unlock your lisp to maximum amount
       of code (other libraries), and correspondingly
       to users
     - Pre-release testing: run tests on the new version,
       compare with results of the previous release,
       ensure there is no regressions and see improvements.
   - distribution maintainer (Quicklisp):
     - release testing: run tests on the same lisp implemetations
       as run on the previouse release, and compare results:
       ensure there is no regressions, and see the improvements.
   - application developer
     (Actually, the application developer as the end user
      of CL infrastructuure, rarely will use testgrid directly.
      He, hopefully, will benefit indirectly, from improved
      stability and quality of the CL world).
      Still, the end user may:
     - see what libraries work on his platform
     - giving his ASDF system see what dependencies
       are broken on what platform

** TODO [6 h] Document the RESULT objects instead of FAILURE. Link to the library reports.
** TODO terminology improvement
  - db format: rename?
                  :libname -> :project
                  :status -> :test-status
                  :log-blob-key -> :test-log-blob-key
                  :log-byte-length -> :test-log-byte-length
  - project name: a keyword, or string? Currently a keyword; but ASDF system names are strings.
  - rename test-grid-testsuites:*all-libs* to *all-testsuites*?
** TODO Apply for a subdomain at common-lisp.net, e.g. test-grid.common-lisp.net,
   It is another way to solve the security issue with HTML injections,
   because in this case web browser keeps test grid reports in different
   security domain than other common-lisp.net pages.
** TODO pivot reports: make row header column always visible
** TODO kind of burndown chart: avearage number of bugs by time
** TODO visual graph of library dependencies, clickable (SVG?),
        so that we can see what libraries are blocked when
        the given library is broken, and what dependencies
        block this library.
        Look for help from http://chart.ravenbrook.com/ ?
** TODO has-regressions-p - cover all the possible cases by unit tests?
** TODO Filters for pivot reports
   Partially done - in a non interactive way.
   I.e. I apply filters when generate reports to publish,
   but there is no way to filter them on WEB. The
   only way for user is to checkout lisp code and
   use it's own filters. Not that bad way, especially
   in the ideology that Lisp is the main interface to
   test results.

   Do we really need WEB UI for filters? If so, it
   is a low priority anyway.

* 0.7.0 Wrap-up the active development phase
** TODO [40 h] Move online log storage to Amazon S3 from Google App Engine?
  We are already close to limit of free GAE resources
  (mostly on datastore write operations, several of which
  are performed for every uploaded log, and when testing
  quicklisp we upload thousands of logs).

  Payed GAE plan costs minimum $15 per month.

  Amazon S3 costs $0.12 per GB per month - much cheaper
  (whole quicklisp by singl lisp implementation produces
  2-5 MB of logs).

  Also we have seen GAE stability/user support issues.

  Problem: uploading logs is easy usin zs3 library,
  but how to assing unique identifiers to them?
  S3 doesn't provide such a functionality. We would
  like to avoid another service only for identifier
  generation. Randome identifiers seems good, but
  we must resovle possible collisions. Maybe calculate
  MD5 for every log before submit and compare with
  ETag returned by S3 in HTTP header? Can it help?

** TODO [40+ h] Immediate test results avaiability, without waiting for admin
   - Store test results locally?
   - Provide a script example, whcih after completing the tests
     generates necessary reports from local test results
     (optionally merged with the global db)
   - Or maybe instead create a server with accepts results
     and makes them available without participation of admin?
** TODO [24 h] document the code base
** TODO [8 h] security: agent runs lot of code provided by unknown peple
   Discuss with Zach, what we know about these people
   and what level of confidence we have in their code.
   This includes:
   - confidence in their good intentions
   - confidence their code don't open unintentional doors to the machine
     (e.g. opens a socker, receives s-expression from it and executes)

   Anyway, the final solution will most likely be to advice
   contributors to run agent under a separate user on their OSes.
* 1.1.0 Install more lisps on my VPS
  I already have acl 8.2a express, ccl 1.8, sbcl 1.57, ecl from git, cmucl 20c
** DONE ABCL
   CLOSED: [2012-08-20 Пн 01:48]
** TODO CLISP (build a multithreaded version)
* 1.2.0 Add more test suites
** TODO add testsuites of more libraries from quicklisp

    See the following files in the "docs" directory:

    test-systems - list of all the ASDF systems in Quicklisp
           with a word "test" in the system name;
           ordered by the project download count.

    detect-test-systems.lisp - the lisp code which
          generated the test-systems file

    quicklisp-download-statistics-2012.txt - quiclisp download statistics

    coverage.org - information about the libraries already reviewed:
          whether it is added to test grid, and if not added - why
         (no test suite, needs manual configuration, hangs, etc.)
          The libraries are ordered in alphabetical order.

** TODO create drakma test suite - will ensure drakma works on all the lisps.
    Drakma test suite is a must. HTTP client today is as vital thing
    as file system access. It should work on all the lisps.
    Create a test suite, the simples one - download one file
    form common-lisp.net. And make sure it works on all the lisps.
* 1.3.1 Add ANSI test suite?
  Does not depend on quicklisp distro version; but BTW may be distirbuted via quicklisp.
* 1.4.0 Test source control HEADs of libraries, not only quicklisp releases
** TODO a way to specify lib-wold as a quicklisp version with some
   library versions overriden (checkout this particular
   libraries from the scm), so that library author can quickly
   get test result for his changes (fixes)  in scm.
   An implementation idea to consider: almost every scm allows
   to download asnapshot via http, so the quicklisp http machinery may
   be reused here, whithout running a shell command for
   checkout.
   40h

* 1.5.0 For all the libraries which need specific environment
   (like cffi, cl-sql) correctly detect the absense of required
   envorinment and return :NO-RESOURCE status and provide guiding message to the
   user how to configure them (log to the output test output?).

   This may be implemented by invoking generic function
   (test-grid-testsuites:check-enviroment <library-name> <test-enviroment-object>) => :NO-RESOURCE or :OK,
   by default returns :OK, but the library maintainer
   may define a method for his library which checks for available envoriment
   and return :NO-RESOURCE, or if the enviroment is OK
   returns :OK and may store some data on the test-envormment-object.

   Then (test-grid-testsuites:libtest <library-name> <test-enviroment-object>) is
   called by agent. So the check-envoronment method may pass enviroment
   information (for examle DB connection parametrs for cl-sql) to the test suite.

   Also we need to define a way for check-enviromnent to be configured
   by the end-user who runs the agent, because every installation
   may have different DB connection parameters. For example, check-enviroment
   may load a file <workdir>/test-configs/<library-name>-config.lisp.
   This file is expected to be provided by the user who runs agant
   and is willing to spend an extra effort to contribute test
   results for these libraries (this is optional of course).

   We may provide only the API and leave the implementation
   of check-environment methods to the library maintainers, because
   othersize it may take very long time for us to impelement
   it for all such libraries.

   Although, for the most important libraries which don't have
   enough maintainers we could provide implementation.
* agent postponed issues
** TODO Introduce an option to limit agent run time
  Use case: someone wants to run agents at night, but have
  the machine free from agent during dayly work.
  We will provide and option the user can configure in run-agent.lisp
  which limits agent run time so that agent exits after this duration.

  Before terminating agent should sumbit the results accumulated to server
  (even partial test runs). This is necessary becase we can not
  be sure the user will ever start the agent again.

  This also means that if next time agent is started, it should
  know what part of test run is completed, and continue for
  remaining projects (record the completenes status
  per library in persistence.lisp instead of whole
  quicklisp distros?)
** TODO A "quit" command for soft termination of the agent instead of killing it
   Will ensure agent finishes only afther all his child processes
   are finished, so that starting agent again is safe.

   How the command should be sent to agent? Via web interface?
   Lisp command from REPL?

** TODO foreign library load errors should be recognized and represented
   in test results (maybe as :no-resource status, but it's better
   to have a special status, including the library name. that way
   we will have up to date list of foreign libraries necessary
   to have quicklisp fully working).

   Catch CFFI conditions, and in case of ABCL, failure to load JNA classes.
   This should be done for load test and for testsuite run.

   After this is implemented, it is desirable to re-run the tests on
   the current and the previous Quicklisps, so that we don't redundant
   items in the diff report (what previous was a load failure
   now becomes :no-resource - not a failure).
** TODO test run duration should be decreased by the time of hibernation
** TODO memoization of the implementation-identifier generic function is not portable
   in particular, it's known that fare-memoization can't memoize it on ACL,
   see https://groups.google.com/d/topic/cl-test-grid/Vnl3kHJbQ0M/discussion
** TODO when logging the name of a library currently being tested, log also it's number in the
   total number of libraries, e.g. [41 of 56].
** TODO remove the old test-runs, quicklisp directordires and ~/cl-test-grid-settings.lisp
   Do it autmatically, or send email to all the contributors, or just ignore this issue
** TODO contributor monthly summary.
   Now that test grid agent can be run by cron, sending confirmation
   email to contributor for every test result doesn't make sense,
   because the contributor is anaware when testing happens. But providing
   feedback is necessary. We may send a monthly digest to contributor
   summarizing the test results received from his agent(s). May be implemented
   as a cron task running say at the 8th of every month (so that admin has
   time to commit all the resutls to db.lisp and the digest
   producer task sees them). Admin should be BCC'ed in these emails.
   Should it be a single email for all contributors and the mailing list,
   or each contributor should be emailed individually?
** TODO a parameter to the main function: limit the maximum time the agent works
** DONE ensure the tesg-grid-testsuites code is recompiled when necessary
   CLOSED: [2012-08-15 Ср 19:11]
   The libraries being tested are recompiled at every test run.
   It would be good to ensure test-grid-testsuites code is also correctly
   recompiled.
   Related thread on asdf-devel:
   http://lists.common-lisp.net/pipermail/asdf-devel/2012-July/002548.html
** TODO Admin stores a hashmap for lisps to be tested (or skipped)
    by particular agent in the aget sources (note, the agent
    updates the source every time from git) This allows to distribute work
    between agents having overlaping sets of lisp implementations.
    Need a mechanizm for announcing the lisps present on
    agent (probably just add agent-id to the test run
    description submitted form agent to admin, and this as an announcement).
    As the compilers versions are changed, probably the
    hashmap to store responsibility specifications should
    contain not full lisp implementation identifier,
    but only generic name, like SBCL instead of SBCL 1.0.57.
    But allow for ECL-bytecode to be distingueshed from
    ECL-lisp-to-c. I.e. in the end we can get some kind
    of patterns for lisp implementation identifier. And
    the identifier will be a structured object, not just
    a string; provably it will even contains *features*
    of the lisp implementaion.
** TODO Agent: retry when test results upload failed.
** TODO recompile cl-test-grid-agent sources at every agetn run?
   As currently ASDF doesn't rebuild depending libraries
   when the libraries they depend on changed (add
   links to this TODO item when Internet connection
   will be up)
   Related thread on asdf-devel:
   http://lists.common-lisp.net/pipermail/asdf-devel/2012-July/002548.html
** TODO kill process tree on unix in case the test suite exceeded timeout
   Currenlty we only kill the lisp process, but not it's children.
   Some test suites may start other programs, and it makes sense
   to kill the testsuite child process too. Implementation hint:
   the most portable API on unix to find out child processes,
   as it seems to be, is the ps program. We will need to
   implement a shell script killtree.sh <pid> which uses
   ps to find all descendents and kill them. Portable format
   of ps arguments should be used.
** TODO move test-grid::print-log-footer to the test-grid-agent package,
   and call it only form the agent process, not from the child, test suite
   running, process.
** TODO consider what test suite timeout value is the best (30 mins currently)
** DONE backtrace in logs
   CLOSED: [2012-08-15 Ср 19:09]
** TODO should the lisp-process-timeout condition inherit from serous-condition, error, or just condition?

** DONE Prevent child lisp process entering debugger.
   CLOSED: [2012-08-15 Ср 19:09]
   Note, different lisps treat unhangled signals during -eval
   differently: ECL exits with status 1, CCL enters debugger
   and hangs.
** TODO program parameters escaping is not perfect. When we
   run CLISP as an external process, it can not stand
   string literals with " inside.
** TODO enable/disable program parameters escapting depending on the
   external-program behaviour (consider also using input stream
   of the lisp process, or a temporary file)
** TODO prevent test run directory names conflict (currently they
   are named by timestamp with resolution to seconds)
** TODO temp file naming: ensure unique [probably specify random-state]
** TODO persistence.lisp format - sort and newline for every record

* User Requests
** TODO Vladimir Sedach: test multithreaded CLISP
   (less important now as Vladimir already installed such lisp on his
   machine and contributes tests)
** TODO Luis Oliveira: buld library heads from source control
* Backlog
** TODO Project dependencies info is hardcoded from quicklisp 2012-09-09. Make it more flexible
   and use the dependency info for the quicklisp we generate report for.
** TODO Child processes collision if agent is restarted very soon after it was killed.
   Agent is pretty resistent to restarts. If it is killed
   and started again, it can continue test run from the point
   reached previously.
   It prevents of starting of several agent instances by "locking"
   via opening a TCP port.
   If laptop is hibernated, after waking up agent re-runs the
   testsuite interrupted by hibernation (to avoid possible
   problems with lost network connections of the testsuite,
   and similar).

   But there is one problem. If we kill agant, we don't
   kill its child processes running tests.
   If we start another agent before the child process finishes
   (completes the testuite or loads the ASDF system), then
   new agent is anaware about the child process, and may start
   new process with the same task. These two child processes,
   the old one and the new one, may intefrere, for example
   thying to write to the same .fasl file, and to the same
   log file.

   How to solve this?
   - To solve what exactly?
   - To ensure, the child process run by new agent,
     the result of which finally gets into the DB,
     is not affected by obsolete child processes
     of the old agent.

** TODO Rebuild the free lisps from source control daily, before running test-grid-agent
** TODO Enable HTTP caching for library test logs (good recipe: https://developers.google.com/speed/docs/best-practices/caching)
** TODO add CCL revision to the version string (I have impression
   that CCL versions checked out at different time from the official release SVN
   svn co http://svn.clozure.com/publicsvn/openmcl/release/1.8/darwinx86/ccl
   may be different. I.e. despite it is called "release 1.8", the mainteiners
   commit fixes there, and the version string we use now - "ccl-1.8-f95-linux-x86",
   does not reflect this. In other words, our version string does not
   identify CCL uniquly.
** TODO code coverage: SBCL provides sb-cover. Integrate it somehow
        and publish in the reports.
        How?
        - extend the lib-result object with one more field, percentage 
          of the covered lines?
        - separate report?
        - or just output the information into the log?
** TODO osicat: automate the :no-resource condition
** TODO ABCL, cffi tests: return :no-resource if JNA is not available
** TODO cffi tests: return :no-resource if C compilation fails on linux
** TODO cl-fad and flexi-streams use c:\tmp as a temporary directory
   on Windows; it's not very good. Maybe try to provide them
   with a temporary directory inside of the cl-test-grid working
   dir?
** DONE Do not allow empty contributor contact in test results. Instead
   CLOSED: [2012-08-20 Пн 01:56]
   always ask the contributor to provide something, nickname,
   whatever.
** TODO quicklisp distro version in report headers may be a link to
   list of library versions in this ql version
   (like this: http://www.quicklisp.org/beta/releases.html, but
   it's only for the latest QL).
** TODO report overview: change "represents every test run as a separate row"  :report:overview:
   to
   "represents every <tt>test-grid:run-tests</tt> as a separate row"
   (after user will know this command from the main project description)
   ?
** TODO Description of CSV report may link to an example of the CSV report  :report:overview:
   imported to a Google Spreadsheet
   with pivot calculating avearage duration of 
   tests for every library.
** TODO spell check the reports-overview                    :report:overview:
** TODO quick access to the test run info from the pivot report table cell  :report:pivot:
   (or maybe just print the test run info to the log, like a header;
    but it is a duplication and also we will have invonviniences
    if we want to modify this infromation in the lob BLOB)
** TODO reduce non cl-test-grid output in the console (quicklisp output,
   compiler output, etc), so that cl-test-grid messages to the user
   are better visible.
** TODO Limit library output file size (how?).
** TODO finalize the terminology we use in the code
   to refer our main data:
   - test status for a particular library
   - library test result object (includes the status
     as well as log length, the key of the log
     in the online blob store, probably the
     library test duration)
   - list of library test results in a particular test
     run
   - test run description, consists of lisp name,
     libraries set (think quicklisp distro),
     the user contacts, total test run duration,
     etc.
** TODO when GAE quotas (for requests, emails, anything else)
   are exceeded, recognize it and display a meaningfull
   message to the user.
** TODO usocket test suite might need manual configuration,
   see their README. Distinguish the case
   when the manual configuration hasn't been
   performed and return :no-resource status.
** TODO An utility to delete blobs not used in db.lisp from the blobstore :server:
